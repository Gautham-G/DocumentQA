{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e4aa58",
   "metadata": {},
   "source": [
    "## Trial on using LangChain for Document based Question Answering\n",
    "\n",
    "* Project structure\n",
    "    * documents\n",
    "        * Contains all documents you want to do QA over\n",
    "    * DocSearch.ipynb\n",
    "        * Contains LangChain + OpenAI implementation of QA over documents\n",
    "\n",
    "* Future steps :\n",
    "    * Include utility to scrape image from pdf (Ex: tool measurements)\n",
    "    * Perform Image to Text on all images and insert text in appropriate positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d78d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Env var OPENAI_API_KEY that we use for the llm\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Insert Key Here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8166dfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in /Users/gauthamgururajan/opt/anaconda3/lib/python3.8/site-packages (1.16.3)\n",
      "Requirement already satisfied: pillow in /Users/gauthamgururajan/opt/anaconda3/lib/python3.8/site-packages (from pdf2image) (8.2.0)\n",
      "Requirement already satisfied: pytesseract in /Users/gauthamgururajan/opt/anaconda3/lib/python3.8/site-packages (0.3.10)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /Users/gauthamgururajan/opt/anaconda3/lib/python3.8/site-packages (from pytesseract) (8.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/gauthamgururajan/opt/anaconda3/lib/python3.8/site-packages (from pytesseract) (23.1)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (add others based on errors - can ignore allennlp version warnings)\n",
    "\n",
    "!pip install --upgrade langchain openai -q\n",
    "!pip install unstructured -q\n",
    "!pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2 -q\n",
    "!pip install tiktoken -q\n",
    "!pip install pdf2image\n",
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a81ac039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries pertaining to QA & Text loading\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# QA & Text loader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# Import vectorstore retriever\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "# parse through directory (can use pdf or text files)\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# for text chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# emb for similarity search\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Chat model\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c14890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse through documents\n",
    "\n",
    "directory = 'documents/'\n",
    "\n",
    "def load_documents(directory):\n",
    "  loader = DirectoryLoader(directory)\n",
    "  documents = loader.load()\n",
    "  return documents\n",
    "\n",
    "documents = load_documents(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "714623d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents based on a specific chunk size\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=20):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "docs = split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5494fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44f0a5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "# Use ChromaDB as vectorstore https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/chroma.html\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "index = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26223b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply similarity search with the query (and the docs in the db)\n",
    "\n",
    "def get_similiar_documents(query, k=2, score=False):\n",
    "  if score:\n",
    "    similar_docs = index.similarity_search_with_score(query, k=k)\n",
    "  else:\n",
    "    similar_docs = index.similarity_search(query, k=k)\n",
    "  return similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97839ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# Use similar documents as context to generate an answer with the llm\n",
    "def get_answer(query):\n",
    "  similar_docs = get_similiar_documents(query)\n",
    "  answer = chain.run(input_documents=similar_docs, question=query)\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08d24aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gautham is a person who introduced himself as an MS CSE student at Georgia Tech and mentioned that he loves NLP.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is Gautham?\"\n",
    "get_answer(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
